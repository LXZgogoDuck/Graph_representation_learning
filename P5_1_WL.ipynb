{"cells":[{"cell_type":"markdown","metadata":{"id":"O12_NFdOzdlD"},"source":["# **Practical 5**\n","\n","Welcome to the last practical for Graph Representation Learning.\n","\n","We will be implementing the 1-WL hash algorithm that is described in the lectures and testing it on several graphs and GNNs.\n","\n","The main goal of the practical is creating a working implementation of the 1-WL hash algorithm and understanding its applicability and limitations.\n","\n","The notebook is divided into sections, each of which comes with complete or partially completed code. Before each snippet of code there will be a description of what we are about to implement. The sections of code you need to complete are marked as Tasks.\n","\n","Please ensure that you operate within the framework given in the notebook and bring any questions you may have to the practical demonstrators. We suggest that you DO NOT edit code that is a part of the framework, since this will make it more difficult for demonstrators to assist if your code is broken."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3650,"status":"ok","timestamp":1700482678368,"user":{"displayName":"Emily Jin","userId":"00213674014052790913"},"user_tz":0},"id":"8YbmazR-2n-L","outputId":"cbdf0a86-ff56-40e4-c606-8a0c05af7e87"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.4.0\n"]}],"source":["# Check PyTorch version installed on this system\n","!python -c \"import torch; print(torch.__version__)\""]},{"cell_type":"code","execution_count":2,"metadata":{"id":"n3wuc62T2pqt"},"outputs":[],"source":["%%capture\n","# Download the corresponding PyTorch Geometric module\n","\"\"\"\n","Assign to TORCH with what you get from the cell above. E.g., export TORCH=1.12.1+cu113\n","\"\"\"\n","%env TORCH=2.0.1+cu118\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install torch-geometric"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4838,"status":"ok","timestamp":1700482705809,"user":{"displayName":"Emily Jin","userId":"00213674014052790913"},"user_tz":0},"id":"LhDlsXipzg8M","outputId":"5510bc8f-51d8-4280-f18a-24b9cab4d438"},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch_geometric.utils import from_networkx\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import Sequential, GCNConv, global_mean_pool\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","rng = np.random.default_rng()"]},{"cell_type":"markdown","metadata":{"id":"Ez7WXFaZz4De"},"source":["# **Part 1: Weisfeiler Lehman Graph Hash**"]},{"cell_type":"markdown","metadata":{"id":"IWHgG_5zPIkc"},"source":["## **Task 1.1: Generate graph pairs using NetworkX**\n","\n","For $n$ between 6 and 15, generate all pairs of graphs $(\\mathcal{C_n}, \\mathcal{D}_{n,i}))$, where $\\mathcal{C}_n$ is a cycle on $n$ nodes and $\\mathcal{D}_{n,i}$ is the disjoint union of two cycles, with $n - i$ and $i$ nodes in total (of course the minimum number of nodes in each single connected component you build should be $> 2$). You can use the functions provided by networkx. We suggest you build on top of `networkx.cycle_graph`."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3\n","4\n","5\n"]}],"source":["for j in range(3, 6):\n","    print (j)\n","for k in range(3, 3):\n","    print(k)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Vva-OtQB0ONB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated 55 graph pairs.\n"]}],"source":["# The range of different graph sizes\n","size_range = range(6, 16)\n","\n","# The list of all graph pairs\n","graph_pairs = []\n","Cns = []\n","\n","for n in size_range:\n","    Cn = nx.cycle_graph(n)\n","    \n","    for i in range(3, n-2): \n","        # Generate the two cycle graphs for Dn,i\n","        Dni_1 = nx.cycle_graph(n - i)  \n","        Dni_2 = nx.cycle_graph(i)     \n","        \n","        # Take the disjoint union\n","        Dni = nx.disjoint_union(Dni_1, Dni_2)\n","        \n","        graph_pairs.append((Cn, Dni))\n","\n","print(f\"Generated {len(graph_pairs)} graph pairs.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"FYbqZs8RFODw"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["### DO NOT MODIFY\n","\n","# Display a random pair\n","fig, axs = plt.subplots(1, 2)\n","pair = random.choice(graph_pairs)\n","for i in range(2):\n","    nx.draw(pair[i], ax=axs[i])\n","    axs[i].set_title(f\"Graph {i+1}\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"SInnrIEhFtlS"},"source":["## **Task 1.2: Implement the Weisfeiler Lehman (WL) graph hash**\n","\n","Implement the function `weisfeiler_lehman_graph_hash` that takes in input a graph $\\mathcal{G}$ and return the hash $WL(\\mathcal{G})$. Use the constant $c = 1$ as the label for each node. For this task, you **cannot** use the utilities provided by the networkx library (except to convert from graphs to tensors if necessary)."]},{"cell_type":"code","execution_count":69,"metadata":{"id":"courOsIWGGxJ"},"outputs":[],"source":["import hashlib\n","import networkx as nx\n","\n","def weisfeiler_lehman_graph_hash(graph, extra_elements = None, max_iter=10):\n","    \n","    if(extra_elements == None):\n","        labels = {node: \"1\" for node in graph.nodes}\n","    else:\n","        labels = {node: \"1\" + str(extra_elements[node]) for node in graph.nodes}  # accept and extra element degree\n","    \n","    \n","    def hash_label(label):\n","        return hashlib.md5(label.encode('utf-8')).hexdigest()\n","    \n","    for _ in range(max_iter):\n","        new_labels = {}\n","        \n","        for node in graph.nodes:\n","            neighbor_labels = [labels[neighbor] for neighbor in graph.neighbors(node)]\n","            combined_label = str(labels[node]) + ''.join(sorted(neighbor_labels))\n","            new_labels[node] = hash_label(combined_label)\n","\n","        labels = new_labels\n","    \n","    final_labels = sorted(labels.values())\n","    return hashlib.md5(''.join(final_labels).encode('utf-8')).hexdigest()\n"]},{"cell_type":"markdown","metadata":{"id":"EQG5P3EQ0Ron"},"source":["Let's do a sanity check to make sure that the members of each pair previously generated are 1-WL indistinguishable:"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"cbQ_cD4n0UY9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of graph pairs: 55\n","Number of 1-WL indistinguishable pairs: 55\n"]}],"source":["### DO NOT MODIFY\n","\n","wl_indistinguishable_pairs = 0\n","for pair in graph_pairs:\n","    hash0 = weisfeiler_lehman_graph_hash(pair[0])\n","    hash1 = weisfeiler_lehman_graph_hash(pair[1])\n","    wl_indistinguishable_pairs += (hash0 == hash1)\n","\n","# Print the number of pairs produced\n","print(f\"Number of graph pairs: {len(graph_pairs)}\")\n","print(f\"Number of 1-WL indistinguishable pairs: {wl_indistinguishable_pairs}\")"]},{"cell_type":"markdown","metadata":{"id":"IHC26nBz44MC"},"source":["# Part 2: WL with extra node information"]},{"cell_type":"markdown","metadata":{"id":"7Qej5u5JGwwv"},"source":["## **Task 2.1: Updating the hash function**\n","\n","Modify the `weisfeiler_lehman_graph_hash` to accept an optional extra element corresponding to the features to assign to each node to be used to compute the final hash."]},{"cell_type":"markdown","metadata":{"id":"0ZlwqIRZIdN1"},"source":["### Task 2.1.1\n","Use the node degree as initial label to compute the WL hash. What do you expect to change compared to before? Why?"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"sa_7JQgeI8CU"},"outputs":[],"source":["def node_degrees(graph):\n","  \"\"\"Returns a list with the degree of each node in graph\"\"\"\n","  list =  {node: str(degree) for node, degree in graph.degree()} # dictionary for (node, degree) pair\n","  print(list)\n","  return list\n"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"zQt7k5VZJNf-"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","{0: '2', 1: '2', 2: '2', 3: '2', 4: '2', 5: '2', 6: '2', 7: '2', 8: '2', 9: '2', 10: '2', 11: '2', 12: '2', 13: '2', 14: '2'}\n","Number of graph pairs: 55\n","Number of 1-WL indistinguishable pairs whenusing the node degree as label:\n"," 55\n"]}],"source":["### DO NOT MODIFY\n","\n","wl_indistinguishable_pairs_with_degree = 0\n","for pair in graph_pairs:\n","    hash0 = weisfeiler_lehman_graph_hash(pair[0], node_degrees(pair[0]))\n","    hash1 = weisfeiler_lehman_graph_hash(pair[1], node_degrees(pair[1]))\n","    wl_indistinguishable_pairs_with_degree += (hash0 == hash1)\n","\n","# Print the number of pairs produced\n","print(f\"Number of graph pairs: {len(graph_pairs)}\")\n","print(f\"Number of 1-WL indistinguishable pairs when\"\n","      f\"using the node degree as label:\\n {wl_indistinguishable_pairs_with_degree}\")"]},{"cell_type":"markdown","metadata":{"id":"kXIr5wFmJtpC"},"source":["### Task 2.1.2\n","Modify the initial label of each node $N_i$ such that it now contains the shortest path length from $N_i$ to $N_j$. Run `weisfeiler_lehman_graph_hash` using the new labels."]},{"cell_type":"code","execution_count":65,"metadata":{"id":"yA4FEAhjK3NB"},"outputs":[],"source":["def node_shortest_paths(graph):\n","  shortest_paths = {}\n","    \n","  for node in graph.nodes():\n","      shortest_paths[node] = nx.single_source_shortest_path_length(graph, node)\n","      \n","  return shortest_paths"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"4LxB8sp-LWKI"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of graph pairs: 55\n","Number of 1-WL indistinguishable pairs whenusing the shortest path lenghts as label:\n"," 0\n"]}],"source":["### DO NOT MODIFY\n","\n","wl_indistinguishable_pairs_with_shortest_path = 0\n","for pair in graph_pairs:\n","    hash0 = weisfeiler_lehman_graph_hash(pair[0], node_shortest_paths(pair[0]))\n","    hash1 = weisfeiler_lehman_graph_hash(pair[1], node_shortest_paths(pair[1]))\n","    wl_indistinguishable_pairs_with_shortest_path += (hash0 == hash1)\n","\n","# Print the number of pairs produced\n","print(f\"Number of graph pairs: {len(graph_pairs)}\")\n","print(f\"Number of 1-WL indistinguishable pairs when\"\n","      f\"using the shortest path lenghts as label:\\n {wl_indistinguishable_pairs_with_shortest_path}\")"]},{"cell_type":"markdown","metadata":{"id":"cA6FogSHGnOq"},"source":["# **Part 3: Building a GNN**"]},{"cell_type":"markdown","metadata":{"id":"4kBIdkokGtbA"},"source":["## **Task 3.1: Converting the graphs from Task 1.1 to PyTorch Geometric objects**\n","\n","Let's turn each graph into `torch_geometric.data.Data` objects, with some input features `x` and output features `y`.\n","Each previously generated pair should be converted to two Data objects, one for the cycle graph and one for the disjoint union one. The features `x` corresponds to the labels of each node; we will use the same label for each node (e.g., an array of 50 elements each set to 1). The output `y` should be 1 for cycle graphs and 0 for disjoint graphs.\n","\n","(Look at the function `from_networkx`)"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"2svuBMcpGrUX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[6, 50], edge_index=[2, 6], y=[1]) tensor([1])\n","Data(x=[6, 50], edge_index=[2, 6], y=[1]) tensor([0])\n","Total number of graphs in dataset: 110\n"]}],"source":["from torch_geometric.data import Data\n","import torch\n","\n","# The list to store the Data objects\n","dataset = []\n","\n","for pair in graph_pairs:\n","    for i, graph in enumerate(pair):\n","        edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()  \n","        node_features = torch.ones((graph.number_of_nodes(), 50), dtype=torch.float)  # 1 feature per node\n","        \n","        label = 1 if i == 0 else 0\n","        data = Data(x=node_features, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n","        \n","        dataset.append(data)\n","\n","print(dataset[0], dataset[0].y)\n","print(dataset[1], dataset[1].y)\n","print(f\"Total number of graphs in dataset: {len(dataset)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"lCHkIGI1GzUG"},"source":["## **Part 3.2: Defining the model**\n","Let's define our graph neural network. First, we define a module for doing mean pooling."]},{"cell_type":"code","execution_count":109,"metadata":{"id":"X-2yv-29GrRf"},"outputs":[],"source":["class GlobalMeanPool(nn.Module):\n","    \"\"\"Global mean pool layer.\"\"\"\n","\n","    def forward(self, x, batch=None, size=None):\n","\n","        # If we don't get the batch vector, set it to zeros.\n","        if batch is None:\n","            batch = x.new_zeros(x.size(0), dtype=torch.int64)\n","\n","        return global_mean_pool(x, batch, size)"]},{"cell_type":"markdown","metadata":{"id":"X7opxSRFG355"},"source":["This is the base GNN model. The function _layer_sequence specifies the list of modules which define the model."]},{"cell_type":"code","execution_count":110,"metadata":{"id":"DrfFeTmaGrPU"},"outputs":[],"source":["class GraphSequenceModel(nn.Module):\n","    \"\"\"A GNN consisting of a stack of layers.\"\"\"\n","\n","    def __init__(self, *args, **kwargs):\n","        super().__init__()\n","        sequence = self._layer_sequence(*args, **kwargs)\n","        self.stack = Sequential(\"x, edge_index, batch\", sequence)\n","\n","    def forward(self, batch):\n","        return self.stack.forward(batch.x, batch.edge_index, batch.batch)\n","\n","    @staticmethod\n","    def _weight_reset(module):\n","        if isinstance(module, GCNConv) or isinstance(module, nn.Linear):\n","            module.reset_parameters()\n","\n","    def reset_parameters(self):\n","        return self.stack.apply(type(self)._weight_reset)"]},{"cell_type":"markdown","metadata":{"id":"2IJTxiATG5_t"},"source":["Finally, here is the model specification itself:"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"OqF39c80GrDL"},"outputs":[],"source":["class MPNN(GraphSequenceModel):\n","    \"\"\"An MPNN with a `num_layers` message passing layers, then an MLP.\"\"\"\n","\n","    def _layer_sequence(self, num_layers=16): # increase to num_layers = 32 \n","\n","        # The sequence of layers\n","        sequence = []\n","\n","        # Add `num_layers` message passing layers\n","        for i in range(num_layers):\n","            sequence.append((GCNConv(50, 50), f\"x, edge_index -> x\"))\n","            sequence.append(nn.ReLU())\n","\n","        # A global mean pool layer\n","        sequence.append((GlobalMeanPool(), f\"x, batch -> x\"))\n","\n","        # Add an MLP at the end\n","        sequence.extend([\n","            (nn.Linear(50, 70), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(70, 25), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(25,2), \"x -> x\")\n","        ])\n","\n","        return sequence"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["from torch_geometric.nn import GATConv\n","\n","class GATModel(GraphSequenceModel):\n","    def _layer_sequence(self, num_layers=4):\n","        sequence = []\n","        for i in range(num_layers):\n","            sequence.append((GATConv(50, 50), f\"x, edge_index -> x\"))\n","            sequence.append(nn.ReLU())\n","        sequence.append((GlobalMeanPool(), f\"x, batch -> x\"))\n","        sequence.extend([\n","            (nn.Linear(50, 70), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(70, 25), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(25, 2), \"x -> x\")\n","        ])\n","        return sequence\n","    \n","class MPNN2(GraphSequenceModel):\n","    \"\"\"An MPNN with a `num_layers` message passing layers, then an MLP.\"\"\"\n","\n","    def _layer_sequence(self, num_layers=16): # increase to num_layers = 32 \n","\n","        # The sequence of layers\n","        sequence = []\n","\n","        # Add `num_layers` message passing layers\n","        for i in range(num_layers):\n","            sequence.append((GCNConv(50, 50), f\"x, edge_index -> x\"))\n","            sequence.append(nn.ReLU())\n","\n","        # A global mean pool layer\n","        sequence.append((GlobalMeanPool(), f\"x, batch -> x\"))\n","\n","        # Add an MLP at the end\n","        sequence.extend([\n","            (nn.Linear(50, 70), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(70, 25), \"x -> x\"),\n","            nn.ReLU(),\n","            (nn.Linear(25,2), \"x -> x\")\n","        ])\n","\n","        return sequence\n"]},{"cell_type":"markdown","metadata":{"id":"w74N0a4ZG9Uf"},"source":["Let's now instantiate the model:"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"edtnuZ1LG9lq"},"outputs":[],"source":["model1 = MPNN(num_layers=16).to(device)\n","model2 = MPNN2(num_layers = 16).to(device)"]},{"cell_type":"markdown","metadata":{"id":"9VeNSF2cHBfa"},"source":["## **Part 3.3: Training, testing and cross-validation functions**\n","This is the generic training loop, which does one epoch-worth of training:\n"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"Zt4jkVa6mJRG"},"outputs":[],"source":["def train_epoch(dataloader, model, loss_fn, optimiser):\n","    \"\"\"Do one epoch-worth of training.\"\"\"\n","\n","    # Put the model in training mode\n","    model.train()\n","\n","    # The number of datapoints\n","    size = len(dataloader.dataset)\n","\n","    # Loop over each batch of datapoints\n","    for data in dataloader:\n","\n","        # Set all the gradients to zero\n","        optimiser.zero_grad()\n","\n","        # Make a prediction using the current parameters\n","        pred = model(data)\n","\n","        # Compute the loss for this prediction\n","        loss = loss_fn(pred, data.y)\n","\n","        # Propagate the loss backwards to compute the gradients\n","        loss.backward()\n","\n","        # Do one step of optimisation\n","        optimiser.step()"]},{"cell_type":"markdown","metadata":{"id":"KKynlKpqmUKt"},"source":["This function does a full train on the data:"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"lqSZEAhsHCGs"},"outputs":[],"source":["def train(train_dataloader, test_dataloader, model, loss_fn, optimiser,\n","          epochs=200, output_every=20):\n","    \"\"\"Train a model for a certain number of epochs.\"\"\"\n","\n","    # Loop through the epochs\n","    for t in range(1, epochs+1):\n","\n","        # Do the training for this epoch\n","        train_epoch(train_dataloader, model, loss_fn, optimiser)\n","\n","        # Output the accuracy of the model every so often\n","        if output_every is not None and t % output_every == 0:\n","            print(f\"Epoch {t}\")\n","            print(\"----------------------------\")\n","            print(f\"Train accuracy: {test(train_dataloader, model):%}\")\n","            print(f\"Test accuracy: {test(test_dataloader, model):%}\")\n","            print()"]},{"cell_type":"markdown","metadata":{"id":"d75SYY2qHKw5"},"source":["This function tests the model on the data, and returns the accuracy:"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"CqkcvyoVHBwH"},"outputs":[],"source":["def test(dataloader, model):\n","    \"\"\"Test a model on some data.\"\"\"\n","\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Get the number of datapoints\n","    size = len(dataloader.dataset)\n","\n","    # The number of correct predictions\n","    correct = 0\n","\n","    # We don't want to be computing the gradients\n","    with torch.no_grad():\n","\n","        # Loop through the minibatches\n","        for data in dataloader:\n","\n","            # Compute the model predictions\n","            pred = model(data)\n","\n","            # Update with the number of correct predictions\n","            correct += (pred.argmax(1) == data.y).count_nonzero()\n","\n","    # Compute the accuracy for the whole dataset and return it\n","    return correct / len(dataloader.dataset)"]},{"cell_type":"markdown","metadata":{"id":"8zCwVq53HOVz"},"source":["This function performs cross-validation on the dataset:"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"yYUaNfMpHP3-"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch_geometric.data import DataLoader\n","\n","def cross_validate(dataset, model, loss_fn, optimizer, num_splits=5, batch_size=32, epochs=200, output_every=20):\n","    \"\"\"Use k-fold cross validation to evaluate a model on a dataset.\"\"\"\n","    \n","    # Get the number of graphs\n","    size = len(dataset)\n","\n","    # Ensure dataset size is even. If odd, we can drop one pair or handle it differently\n","    if size % 2 != 0:\n","        print(f\"Warning: Dataset size ({size}) is odd. Dropping one graph.\")\n","        dataset = dataset[:-1]  # Drop the last graph if the dataset size is odd\n","\n","    num_pairs = size // 2  # Each pair consists of two graphs\n","\n","    # Construct a permuter which keeps paired graphs together\n","    pair_permuter = np.random.permutation(np.arange(num_pairs)) * 2  # Multiply by 2 for pairs\n","\n","    graph_permuter = np.empty((size,), dtype=int)\n","    graph_permuter[0::2] = pair_permuter\n","    graph_permuter[1::2] = pair_permuter + 1\n","\n","    # Use the permuter to shuffle the dataset\n","    shuffled_dataset = [dataset[i] for i in graph_permuter]\n","\n","    # Arrays to store the train and test accuracies for each fold\n","    train_accuracies = np.zeros(num_splits)\n","    test_accuracies = np.zeros(num_splits)\n","\n","    # Loop over the folds\n","    for fold in range(num_splits):\n","        print(f\"Fold {fold + 1}\")\n","        print(\"============================\")\n","        print()\n","\n","        # Calculate the current fold segment indices\n","        index_min = int(((num_pairs * fold) // num_splits) * 2)\n","        index_max = int(((num_pairs * (fold + 1)) // num_splits) * 2)\n","\n","        # Split into train and test datasets\n","        train_dataset = shuffled_dataset[:index_min] + shuffled_dataset[index_max:]\n","        test_dataset = shuffled_dataset[index_min:index_max]\n","\n","        # Turn these into torch_geometric dataloaders\n","        train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n","        test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","        # Reset the parameter of the model before training\n","        model.reset_parameters()\n","\n","        # Train with these\n","        train(train_dataloader, test_dataloader, model, loss_fn, optimizer, epochs, output_every)\n","\n","        # Record the test and train accuracies for the trained model\n","        train_accuracies[fold] = test(train_dataloader, model)\n","        test_accuracies[fold] = test(test_dataloader, model)\n","\n","    # Print the Train and test accuracies for each fold\n","    print(f\"{num_splits}-fold validation summary\")\n","    print(\"============================\")\n","    for fold in range(num_splits):\n","        print(f\"Fold {fold + 1}. Train: {train_accuracies[fold]:09.5%} Test: {test_accuracies[fold]:09.5%}\")\n"]},{"cell_type":"markdown","metadata":{"id":"poftURRdHQMU"},"source":["## Task 3.4: Training the model\n","\n","Specify loss and optimiser and train the model using the `cross_validate` function. Use a learning rate of 1e-3 and 100 epochs. What results do you get? Is it possible to improve the architecture to get a better test accuracy? Why?"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"_kmLe-25HU_I"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 73.863637%\n","Test accuracy: 86.363637%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 68.181819%\n","Test accuracy: 63.636363%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 92.045456%\n","Test accuracy: 86.363637%\n","\n","Fold 2\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 75.000000%\n","Test accuracy: 81.818181%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 77.272725%\n","Test accuracy: 63.636363%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 84.090906%\n","Test accuracy: 68.181819%\n","\n","Fold 3\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Fold 4\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 78.409094%\n","Test accuracy: 86.363637%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Fold 5\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","5-fold validation summary\n","============================\n","Fold 1. Train: 92.04546% Test: 86.36364%\n","Fold 2. Train: 84.09091% Test: 68.18182%\n","Fold 3. Train: 50.00000% Test: 50.00000%\n","Fold 4. Train: 50.00000% Test: 50.00000%\n","Fold 5. Train: 50.00000% Test: 50.00000%\n"]}],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n","\n","# Perform cross-validation\n","cross_validate(\n","    dataset=dataset, \n","    model=model1, \n","    loss_fn=loss_fn, \n","    optimizer=optimizer, \n","    num_splits=5, \n","    batch_size=32,\n","    epochs=100,  \n","    output_every=20  \n",")\n"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 97.727275%\n","Test accuracy: 95.454544%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 97.727275%\n","Test accuracy: 95.454544%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 97.727275%\n","Test accuracy: 95.454544%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 92.045456%\n","Test accuracy: 86.363637%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 75.000000%\n","Test accuracy: 68.181819%\n","\n","Fold 2\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 77.272725%\n","Test accuracy: 77.272725%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 92.045456%\n","Test accuracy: 86.363637%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 96.590906%\n","Test accuracy: 86.363637%\n","\n","Fold 3\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 94.318181%\n","Test accuracy: 100.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 88.636363%\n","Test accuracy: 77.272725%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 94.318181%\n","Test accuracy: 100.000000%\n","\n","Fold 4\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Fold 5\n","============================\n","\n","Epoch 20\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 40\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 60\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 80\n","----------------------------\n","Train accuracy: 50.000000%\n","Test accuracy: 50.000000%\n","\n","Epoch 100\n","----------------------------\n","Train accuracy: 80.681819%\n","Test accuracy: 90.909094%\n","\n","5-fold validation summary\n","============================\n","Fold 1. Train: 75.00000% Test: 68.18182%\n","Fold 2. Train: 96.59091% Test: 86.36364%\n","Fold 3. Train: 94.31818% Test: 100.00000%\n","Fold 4. Train: 50.00000% Test: 50.00000%\n","Fold 5. Train: 80.68182% Test: 90.90909%\n"]}],"source":["# try to increase the model depth\n","optimizer = torch.optim.Adam(model1.parameters(), lr=1e-3)\n","\n","# Perform cross-validation\n","cross_validate(\n","    dataset=dataset, \n","    model=model1, \n","    loss_fn=loss_fn, \n","    optimizer=optimizer, \n","    num_splits=5, \n","    batch_size=32,\n","    epochs=100,  \n","    output_every=20  \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
