{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qBOS0ukjxIQ"
      },
      "source": [
        "# Introduction\n",
        "Welcome to Practical 3 for Graph Representation Learning.  In this practical, you are expected to first implement two functions from scratch: **Graph Mini-Batching** and **Global Pooling**. Then, you need to incorporate these two functions into a graph neural network model to solve a **Graph Classification** task.\n",
        "\n",
        "- **Graph Mini-Batching** A mini-batch groups a set of graphs into a unified representation where it can efficiently be processed in parallel.\n",
        "- **Global Pooling** Obtain the graph feature based on all node features in the graph, in which you can use different operations such as summation, mean and max.\n",
        "\n",
        "We will be using [PyTorch](https://pytorch.org/docs/stable/index.html) and [PyG](https://pytorch-geometric.readthedocs.io/en/latest/) for experiments.\n",
        "\n",
        "The notebook is divided into sections, each of which comes with complete or partially completed code. Before each snippet of code there will be a description of what we are about to implement. The sections of code you need to complete are marked as **Tasks**.\n",
        "\n",
        "Please ensure that you operate within the framework given in the notebook and bring any questions you may have to the practical demonstrators. We suggest that you **DO NOT** edit code that is a part of the framework, since this will make it more difficult for demonstrators to assist if your code is broken.\n",
        "\n",
        "Since we are working in a Jupyter Notebook, the code is very interactive. When you're stuck on something, try adding a new block of code below what you're working on and using it to debug your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWwo4htCSNj4"
      },
      "source": [
        "## Installing dependencies\n",
        "First of all, we advise you to enable GPU acceleration for your notebook. This can be done by navigating to `Runtime > Change runtime type > Hardware accelerator (GPU) > Save`. You may getting an error explaining that no GPUs are currently available. This is fine, you don't really need them for this practical, however they'll make your computations significantly faster.\n",
        "\n",
        "Some other tips & tricks:\n",
        "- press `Shift + Enter` to run a cell and move to the next one (`Ctrl + Enter` to only run it)\n",
        "- when you execute a cell, the variables you create are saved into a global namespace. As a consequence, changes in the code will not take effect until you re-run that specific cell.\n",
        "- remember to save your notebook every once in a while!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOALkyBjnFbj"
      },
      "outputs": [],
      "source": [
        "# Download the corresponding PyTorch Geometric module\n",
        "%%capture\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkz6VLjOryE5"
      },
      "source": [
        "# Imports\n",
        "\n",
        "Run the following blocks of code to install and import and the necessary python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wY3B_uB3ry43"
      },
      "outputs": [],
      "source": [
        "# Let's first import all the things we are gonna need for this task\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import scatter\n",
        "from torch_geometric.nn import MessagePassing\n",
        "import torch_geometric.utils as U\n",
        "# torch_geometric only used to load the Cora dataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data.data import Data\n",
        "import torch_geometric.utils as U\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.datasets import TUDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZKndO0hYiKr"
      },
      "source": [
        "\n",
        "# Dataset\n",
        "\n",
        "## Loading MUTAG from TUDataset\n",
        "We will use TUDataset to load the MUTAG dataset, which contains molecular graphs of 188 chemical compounds divided into two classes according to their mutagenic effect on a bacterium.\n",
        "\n",
        "We construct three lists: A, X, Y, which correspond to a list of adj_matrix, a list of node features and a list of graph labels, respectively.\n",
        "\n",
        "Please **DO NOT** modify any part of the following block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "xCTdKEvIobt6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188\n"
          ]
        }
      ],
      "source": [
        "# please **DO NOT** modify  any part of the following code  in this cell\n",
        "raw_dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "batch_size = 32\n",
        "A = []\n",
        "X = []\n",
        "Y = []\n",
        "for graph in raw_dataset:\n",
        "    adj_matrix = U.to_dense_adj(graph.edge_index).squeeze(0)\n",
        "    A.append(adj_matrix)\n",
        "    X.append(graph.x)\n",
        "    Y.append(graph.y)\n",
        "\n",
        "print(len(A))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhI8VnJCvOf0"
      },
      "source": [
        "We can then run the following cell to output the first one element in the three constructed lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "VjKHlRk2tbxU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([17, 17])\n",
            "torch.Size([17, 7])\n",
            "torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "print(A[0].shape)\n",
        "print(X[0].shape)\n",
        "print(Y[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlV9O3MORCTm"
      },
      "source": [
        "## Task 1\n",
        "Define an iterator `graph_mini_batch` that takes in a list of adj_matrix (A), a list of node features (X), a list of graph labels (Y) and a batch_size B=64, and outputs four items $A_B$, $X_B$, $Y_B$ and $\\textsf{Batch}$ each time, such that the batched Adjacency matrices  $A_B$ are stacked in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs), and the batched node features list $X_B$ and the batched graph label list $Y_B$ are simply concatenated in the node dimension, i.e.,\n",
        "\n",
        "\\begin{split}\\mathbf{A_B} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X_B} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y_B} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}.\\end{split}\n",
        "\n",
        "Furthermore, you are expected to output a  **`Batch` vector**, which maps each node to its respective graph in the batch:\n",
        "\n",
        "$$\n",
        "\\textrm{Batch} = [ 0, \\ldots, 0, 1, \\ldots, 1, 2, \\ldots, n, \\ldots, n]\n",
        "$$\n",
        "\n",
        "**Hints:**\n",
        "1. use the keyword **yield** to make your function be an iterator.\n",
        "2. note that the last batch might not have the enough items satisfying the specified batch size, so your function should be able to deal with such a case and have a correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def graph_mini_batch(adj_matrix_list, x_list, y_list, batch_size=64):\n",
        "\n",
        "    num_graphs = len(adj_matrix_list)\n",
        "    # print(num_graphs)\n",
        "\n",
        "    num_batches = int(num_graphs/batch_size)\n",
        "    # print(num_batches)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        adj_batch_list = adj_matrix_list[i:i+batch_size]\n",
        "        x_batch_list = x_list[i:i+batch_size]\n",
        "        y_batch_list = y_list[i:i+batch_size]\n",
        "\n",
        "        # create A_B\n",
        "        total_rows = sum(mat.shape[0] for mat in adj_batch_list)\n",
        "        total_cols = sum(mat.shape[1] for mat in adj_batch_list)\n",
        "\n",
        "        node_counts = [A.shape[0] for A in adj_batch_list]\n",
        "        \n",
        "        A_B = np.zeros((total_rows, total_cols)) # Initialize a large zero matrix\n",
        "        # Fill in each block along the diagonal\n",
        "        row_start, col_start = 0, 0\n",
        "        for mat in adj_batch_list:\n",
        "            rows, cols = mat.shape\n",
        "            A_B[row_start:row_start+rows, col_start:col_start+cols] = mat\n",
        "            row_start += rows\n",
        "            col_start += cols\n",
        "\n",
        "        # create X_B, Y_B\n",
        "        X_B = np.concatenate(x_batch_list)\n",
        "        Y_B = np.concatenate(y_batch_list)\n",
        "\n",
        "        Batch = np.concatenate([[j] * node_counts[j] for j in range(len(adj_batch_list))])\n",
        "        A_B = torch.tensor(A_B)\n",
        "        X_B = torch.tensor(X_B)\n",
        "        Y_B = torch.tensor(Y_B)\n",
        "        Batch = torch.tensor(Batch)\n",
        "\n",
        "        yield A_B, X_B, Y_B, Batch\n",
        "\n",
        "    if (batch_size*num_batches < num_graphs):\n",
        "        n = batch_size*num_batches\n",
        "\n",
        "        adj_batch_list = adj_matrix_list[n:num_graphs]\n",
        "        x_batch_list = x_list[n:num_graphs]\n",
        "        y_batch_list = y_list[n:num_graphs]\n",
        "        \n",
        "        node_counts = [A.shape[0] for A in adj_batch_list]\n",
        "        total_rows = sum(mat.shape[0] for mat in adj_batch_list)\n",
        "        total_cols = sum(mat.shape[1] for mat in adj_batch_list)\n",
        "\n",
        "        A_B = np.zeros((total_rows, total_cols)) \n",
        "        row_start, col_start = 0, 0\n",
        "        for mat in adj_batch_list:\n",
        "            rows, cols = mat.shape\n",
        "            A_B[row_start:row_start+rows, col_start:col_start+cols] = mat\n",
        "            row_start += rows\n",
        "            col_start += cols\n",
        "\n",
        "        X_B = np.concatenate(x_batch_list)\n",
        "        Y_B = np.concatenate(y_batch_list)\n",
        "        Batch = np.concatenate([[j] * node_counts[j] for j in range(len(adj_batch_list))])\n",
        "\n",
        "        A_B = torch.tensor(A_B)\n",
        "        X_B = torch.tensor(X_B)\n",
        "        Y_B = torch.tensor(Y_B)\n",
        "        Batch = torch.tensor(Batch)\n",
        "\n",
        "\n",
        "        yield A_B, X_B, Y_B, Batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import scipy.sparse as sp\n",
        "\n",
        "# def graph_mini_batch(adj_matrix_list, x_list, y_list, batch_size=64):\n",
        "#     num_graphs = len(adj_matrix_list)\n",
        "    \n",
        "#     for i in range(0, num_graphs, batch_size):\n",
        "#         batch_adj = adj_matrix_list[i:i + batch_size]\n",
        "#         batch_features = x_list[i:i + batch_size]\n",
        "#         batch_labels = y_list[i:i + batch_size]\n",
        "        \n",
        "#         batch_adj = [sp.csr_matrix(A) if not sp.issparse(A) else A for A in batch_adj]\n",
        "#         node_counts = [A.shape[0] for A in batch_adj]\n",
        "        \n",
        "#         A_B = sp.block_diag(batch_adj, format='csr')\n",
        "#         X_B = np.vstack(batch_features)\n",
        "#         Y_B = np.concatenate(batch_labels)\n",
        "        \n",
        "#         Batch = np.concatenate([[j] * node_counts[j] for j in range(len(batch_adj))])\n",
        "        \n",
        "#         yield A_B, X_B, Y_B, Batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "dpZQz5Q-zBek"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adj_matrix_size torch.Size([585, 585])\n",
            "x_size torch.Size([585, 7])\n",
            "y.size torch.Size([32])\n",
            "batch.size torch.Size([585])\n",
            "adj_matrix_size torch.Size([591, 591])\n",
            "x_size torch.Size([591, 7])\n",
            "y.size torch.Size([32])\n",
            "batch.size torch.Size([591])\n",
            "adj_matrix_size torch.Size([591, 591])\n",
            "x_size torch.Size([591, 7])\n",
            "y.size torch.Size([32])\n",
            "batch.size torch.Size([591])\n",
            "adj_matrix_size torch.Size([595, 595])\n",
            "x_size torch.Size([595, 7])\n",
            "y.size torch.Size([32])\n",
            "batch.size torch.Size([595])\n",
            "adj_matrix_size torch.Size([590, 590])\n",
            "x_size torch.Size([590, 7])\n",
            "y.size torch.Size([32])\n",
            "batch.size torch.Size([590])\n",
            "adj_matrix_size torch.Size([526, 526])\n",
            "x_size torch.Size([526, 7])\n",
            "y.size torch.Size([28])\n",
            "batch.size torch.Size([526])\n"
          ]
        }
      ],
      "source": [
        "# Test your batch function here\n",
        "for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, batch_size):\n",
        "     print(f\"adj_matrix_size {adj_matrix.size()}\") \n",
        "     print(f\"x_size {x.size()}\")         \n",
        "     print(f\"y.size {y.size()}\")\n",
        "     print(f\"batch.size {batch.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7k4UptPbCf9"
      },
      "source": [
        "## Task 2\n",
        "Define a function `global_sum_pool` which takes a batch of node features and a Batch vector mapping each node to its respective graph in the batch, and outputs a batch of graph representation vectors by summing all node features in a graph.\n",
        "\n",
        "**Hints:** You are allowed to use the function scatter from torch_scatter library. See [here](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter) for a detailed introduction about the usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "i6YFBsNrbdZr"
      },
      "outputs": [],
      "source": [
        "#scaler? sparse matrix? efficency? in practice?\n",
        "def global_sum_pool(x, batch):\n",
        "    \n",
        "    num_graphs = batch.max().item() + 1  # Calculate the number of graphs\n",
        "\n",
        "    graph_representations = scatter(x, batch, dim=0, reduce='sum', dim_size=num_graphs)\n",
        "\n",
        "    return graph_representations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ABuRS36DVn5q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 7])\n",
            "torch.Size([32, 7])\n",
            "torch.Size([32, 7])\n",
            "torch.Size([32, 7])\n",
            "torch.Size([32, 7])\n",
            "torch.Size([28, 7])\n"
          ]
        }
      ],
      "source": [
        "# Test your pooling function, assuming you are given a mini-batch of node features and a batch vector\n",
        "for _, x, _ , batch in graph_mini_batch(A, X, Y, batch_size):\n",
        "      sum_graph_rep =  global_sum_pool(x, batch)\n",
        "      print(sum_graph_rep.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_BV3iHA9Gaw"
      },
      "source": [
        "# Model\n",
        "We now implement a GNN model, `GIN`, which is used to do the graph classification. **DO NOT** change the following block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "UUQGCU9-YQVP"
      },
      "outputs": [],
      "source": [
        "class GINConv(MessagePassing):\n",
        "    def __init__(self, emb_dim):\n",
        "        '''\n",
        "            emb_dim (int): node embedding dimensionality\n",
        "        '''\n",
        "        super(GINConv, self).__init__(aggr = \"add\")\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
        "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x))\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "        return F.relu(x_j)\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "### GNN to generate node embedding\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Output:\n",
        "        node representations\n",
        "    \"\"\"\n",
        "    def __init__(self, num_layer, emb_dim, hidden_dim, drop_ratio = 0, JK = \"last\", residual = False):\n",
        "        '''\n",
        "            emb_dim (int): node embedding dimensionality\n",
        "            num_layer (int): number of GNN message passing layers\n",
        "        '''\n",
        "        super(GIN, self).__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.drop_ratio = drop_ratio\n",
        "        self.JK = JK\n",
        "        ### add residual connection or not\n",
        "        self.residual = residual\n",
        "        if self.num_layer < 2:\n",
        "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
        "\n",
        "        self.embed = torch.nn.Linear(emb_dim, hidden_dim)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.batch_norms = torch.nn.ModuleList()\n",
        "        for layer in range(num_layer):\n",
        "            self.convs.append(GINConv(hidden_dim))\n",
        "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h_list = [self.embed(x)]\n",
        "        for layer in range(self.num_layer):\n",
        "            h = self.convs[layer](h_list[layer], edge_index)\n",
        "            h = self.batch_norms[layer](h)\n",
        "            if layer == self.num_layer - 1:\n",
        "                #remove relu for the last layer\n",
        "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
        "            else:\n",
        "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
        "\n",
        "            if self.residual:\n",
        "                h += h_list[layer]\n",
        "\n",
        "            h_list.append(h)\n",
        "        ### Different implementations of Jk-concat\n",
        "        if self.JK == \"last\":\n",
        "            node_representation = h_list[-1]\n",
        "        elif self.JK == \"sum\":\n",
        "            node_representation = 0\n",
        "            for layer in range(self.num_layer + 1):\n",
        "                node_representation += h_list[layer]\n",
        "\n",
        "        return node_representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIrzU7d_-K1L"
      },
      "source": [
        "### Define the hyperparameters we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "uATxaDKL-QzC"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"input_features\": 7,\n",
        "    \"hidden_features\": 50,\n",
        "    \"num_layers\": 3,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 0,\n",
        "    \"num_epochs\": 100,\n",
        "    \"num_classes\": 2,\n",
        "    \"batch_size\": 62\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX7kDGkY-jdk"
      },
      "source": [
        "Now, we come to the most exciting part, that is, training and evaluating the model based on the graph mini-batch and the graph pooling functions you implemented above.\n",
        "\n",
        "By checking the training time,  you can see the power of the graph batching by changing the batch_size, i.e., from 1 to 64."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "64Mw0rgPeiEA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0, loss=1.020653486251831, accuracy=0.25531914830207825\n",
            "epoch=10, loss=8.111856004688889e-05, accuracy=0.271276593208313\n",
            "epoch=20, loss=2.1278618078213185e-05, accuracy=0.9095744490623474\n",
            "epoch=30, loss=1.1265208740951493e-05, accuracy=0.9521276354789734\n",
            "epoch=40, loss=7.808174814272206e-06, accuracy=0.9521276354789734\n",
            "epoch=50, loss=5.424006303655915e-06, accuracy=0.9680851101875305\n",
            "epoch=60, loss=4.351128154667094e-06, accuracy=0.9680851101875305\n",
            "epoch=70, loss=3.635875600593863e-06, accuracy=0.9680851101875305\n",
            "epoch=80, loss=2.980227009174996e-06, accuracy=0.9680851101875305\n",
            "epoch=90, loss=2.3841823804104934e-06, accuracy=0.9680851101875305\n",
            "time=3.9510109424591064\n"
          ]
        }
      ],
      "source": [
        "begin_time = time.time()\n",
        "\n",
        "model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
        "pooling = global_sum_pool\n",
        "graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
        "if graph_pred_linear is not None:\n",
        "        model_param_group.append(\n",
        "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
        "        )\n",
        "\n",
        "optimizer = torch.optim.AdamW(model_param_group,\n",
        "                                lr=params[\"learning_rate\"],\n",
        "                                weight_decay=params[\"weight_decay\"])\n",
        "for epoch in range(params[\"num_epochs\"]):\n",
        "  model.train()\n",
        "  for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
        "      optimizer.zero_grad()\n",
        "      edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "      nodes = model(x, edge_index)\n",
        "      graph_reps = pooling(nodes, batch)\n",
        "      pred = graph_pred_linear(graph_reps)\n",
        "      loss = loss_fn(pred, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  if epoch % 10 == 0:\n",
        "      model.eval()\n",
        "      correct = 0\n",
        "      total_num = 0\n",
        "      for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
        "        optimizer.zero_grad()\n",
        "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "        nodes = model(x, edge_index)\n",
        "        graph_reps = pooling(nodes, batch)\n",
        "        pred = graph_pred_linear(graph_reps)\n",
        "        correct += (pred.argmax(dim=-1) == y).sum()\n",
        "        total_num += len(y)\n",
        "      print(\"epoch={}, loss={}, accuracy={}\".format(epoch, loss.item(), correct/total_num))\n",
        "print(\"time={}\".format(time.time()-begin_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_sizes = range(1, 65)  \n",
        "execution_times = []\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    # Update the batch size in the parameters dictionary\n",
        "    params[\"batch_size\"] = batch_size\n",
        "    \n",
        "    # Initialize model, pooling function, linear layer, loss, and optimizer\n",
        "    model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
        "    pooling = global_sum_pool\n",
        "    graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
        "    if graph_pred_linear is not None:\n",
        "        model_param_group.append(\n",
        "            {\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]}\n",
        "        )\n",
        "    optimizer = torch.optim.AdamW(model_param_group,\n",
        "                                  lr=params[\"learning_rate\"],\n",
        "                                  weight_decay=params[\"weight_decay\"])\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    for adj_matrix, x, y, batch in graph_mini_batch(A, X, Y, params[\"batch_size\"]):\n",
        "        optimizer.zero_grad()\n",
        "        edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "        nodes = model(x, edge_index)\n",
        "        graph_reps = pooling(nodes, batch)\n",
        "        pred = graph_pred_linear(graph_reps)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    execution_times.append(time.time() - start_time)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(batch_sizes, execution_times, marker='o')\n",
        "plt.xlabel(\"Batch Size\")\n",
        "plt.ylabel(\"Execution Time (seconds)\")\n",
        "plt.title(\"Model Execution Time vs Batch Size\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieNyeHvcVR9D"
      },
      "source": [
        "### Task 3 (Optional)\n",
        "This is an optional task. You are expected to implement 10-Fold Cross-validation. The general procedure is as follows:\n",
        "\n",
        "1. Shuffle the dataset randomly.\n",
        "2. Split the dataset into $k$ groups.\n",
        "For each unique group:\n",
        "  - Take the group as a hold out or test data set\n",
        "  - Take the remaining groups as a training data set\n",
        "  - Fit a model on the training set and evaluate it on the test set.\n",
        "  Retain the evaluation score and discard the model\n",
        "  - Summarize the skill of the model using the sample of model evaluation scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "VeZtBHmhhtX4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n",
            "Fold 1 Accuracy: 0.9474\n",
            "Fold 2/10\n",
            "Fold 2 Accuracy: 0.7895\n",
            "Fold 3/10\n",
            "Fold 3 Accuracy: 0.8421\n",
            "Fold 4/10\n",
            "Fold 4 Accuracy: 0.7895\n",
            "Fold 5/10\n",
            "Fold 5 Accuracy: 0.6842\n",
            "Fold 6/10\n",
            "Fold 6 Accuracy: 0.6842\n",
            "Fold 7/10\n",
            "Fold 7 Accuracy: 0.6842\n",
            "Fold 8/10\n",
            "Fold 8 Accuracy: 0.6842\n",
            "Fold 9/10\n",
            "Fold 9 Accuracy: 0.8333\n",
            "Fold 10/10\n",
            "Fold 10 Accuracy: 0.8889\n",
            "Mean Accuracy: 0.7827, Standard Deviation: 0.0913\n",
            "Total Time: 4.09 seconds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "params = {\n",
        "    \"num_layers\": 3,\n",
        "    \"input_features\": X[0].shape[1],  \n",
        "    \"hidden_features\": 64,\n",
        "    \"num_classes\": len(torch.unique(torch.tensor(Y))), \n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\": 0.0001,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_epochs\": 10,\n",
        "}\n",
        "\n",
        "def train_and_evaluate(A_train, X_train, Y_train, A_test, X_test, Y_test, params):\n",
        "\n",
        "    model = GIN(params[\"num_layers\"], params[\"input_features\"], params[\"hidden_features\"])\n",
        "    graph_pred_linear = torch.nn.Linear(params[\"hidden_features\"], params[\"num_classes\"])\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    model_param_group = [{\"params\": model.parameters(), \"lr\": params[\"learning_rate\"]}]\n",
        "    model_param_group.append({\"params\": graph_pred_linear.parameters(), \"lr\": params[\"learning_rate\"]})\n",
        "    optimizer = optim.AdamW(model_param_group, lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
        "\n",
        "    for epoch in range(params[\"num_epochs\"]):\n",
        "        model.train()\n",
        "        for adj_matrix, x, y, batch in graph_mini_batch(A_train, X_train, Y_train, params[\"batch_size\"]):\n",
        "            optimizer.zero_grad()\n",
        "            edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "            nodes = model(x, edge_index)\n",
        "            graph_reps = global_sum_pool(nodes, batch)\n",
        "            pred = graph_pred_linear(graph_reps)\n",
        "            loss = loss_fn(pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for adj_matrix, x, y, batch in graph_mini_batch(A_test, X_test, Y_test, params[\"batch_size\"]):\n",
        "            edge_index = U.dense_to_sparse(adj_matrix)[0]\n",
        "            nodes = model(x, edge_index)\n",
        "            graph_reps = global_sum_pool(nodes, batch)\n",
        "            pred = graph_pred_linear(graph_reps)\n",
        "            correct += (pred.argmax(dim=-1) == y).sum().item()\n",
        "            total += len(y)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "def cross_validate_model(A, X, Y, params, k=10):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "    \n",
        "    for fold, (train_idx, test_idx) in enumerate(kfold.split(A)):\n",
        "        print(f\"Fold {fold + 1}/{k}\")\n",
        "        \n",
        "        A_train = [A[i] for i in train_idx]\n",
        "        X_train = [X[i] for i in train_idx]\n",
        "        Y_train = [Y[i] for i in train_idx]\n",
        "        A_test = [A[i] for i in test_idx]\n",
        "        X_test = [X[i] for i in test_idx]\n",
        "        Y_test = [Y[i] for i in test_idx]\n",
        "\n",
        "        accuracy = train_and_evaluate(A_train, X_train, Y_train, A_test, X_test, Y_test, params)\n",
        "        scores.append(accuracy)\n",
        "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
        "    \n",
        "    mean_accuracy = np.mean(scores)\n",
        "    std_accuracy = np.std(scores)\n",
        "    print(f\"Mean Accuracy: {mean_accuracy:.4f}, Standard Deviation: {std_accuracy:.4f}\")\n",
        "    return mean_accuracy, std_accuracy\n",
        "\n",
        "begin_time = time.time()\n",
        "mean_accuracy, std_accuracy = cross_validate_model(A, X, Y, params)\n",
        "print(\"Total Time: {:.2f} seconds\".format(time.time() - begin_time))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
